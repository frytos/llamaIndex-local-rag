# üöÄ Runpod Startup Command - Instructions

## Option 1: One-Liner (Recommand√©) ‚≠ê

### Dans l'UI Runpod

Quand tu cr√©es ton pod, dans le champ **"Docker Command"**, colle ceci:

```bash
bash -c "apt-get update -qq && apt-get install -y git && rm -rf /workspace/rag-pipeline && git clone https://github.com/frytos/llamaIndex-local-rag.git /workspace/rag-pipeline && cd /workspace/rag-pipeline && bash scripts/runpod_startup.sh"
```

### Avec Variables d'Environnement (Avanc√©)

Si tu veux customiser le comportement, ajoute ces **Environment Variables** dans l'UI:

| Variable | Description | D√©faut | Exemple |
|----------|-------------|--------|---------|
| `REPO_URL` | URL du repo Git | https://github.com/frytos/llamaIndex-local-rag.git | Ton fork |
| `SETUP_POSTGRES` | Installer PostgreSQL local | 0 | `1` (pour activer) |
| `DOWNLOAD_MODELS` | Pr√©-t√©l√©charger les mod√®les | 0 | `1` (pour activer) |
| `RUN_COMMAND` | Commande √† ex√©cuter apr√®s setup | (none) | `python3 rag_low_level_m1_16gb_verbose.py --help` |
| `KEEP_ALIVE` | Garder le container actif | 0 | `1` (pour debug) |

---

## Option 2: Startup Script dans le Pod

### √âtape 1: Upload le script

Apr√®s avoir cr√©√© ton pod:

```bash
# SSH dans le pod
ssh root@your-pod-ip -p your-port

# Clone le repo
rm -rf /workspace/rag-pipeline && git clone https://github.com/frytos/llamaIndex-local-rag.git /workspace/rag-pipeline
cd /workspace/rag-pipeline

# Rendre le script ex√©cutable
chmod +x scripts/runpod_startup.sh

# Ex√©cuter
bash scripts/runpod_startup.sh
```

### √âtape 2: Avec Variables

```bash
# Setup complet avec PostgreSQL et mod√®les
SETUP_POSTGRES=1 \
DOWNLOAD_MODELS=1 \
bash scripts/runpod_startup.sh
```

---

## Option 3: Configuration Automatique Compl√®te

### Dans Runpod UI - Configuration du Pod

**1. Template:** Runpod PyTorch 2.4.0

**2. GPU:** RTX 4090 (24GB)

**3. Container Disk:** 50 GB

**4. Volume Disk:** 100 GB

**5. Expose Ports:**
```
5432,8000,22
```

**6. Environment Variables:**
```bash
SETUP_POSTGRES=1
DOWNLOAD_MODELS=1
EMBED_BACKEND=torch
N_GPU_LAYERS=99
N_BATCH=512
CTX=16384
PGHOST=localhost
PGUSER=fryt
PGPASSWORD=frytos
DB_NAME=vector_db
PGTABLE=messenger_runpod
HF_HOME=/workspace/huggingface_cache
```

**7. Docker Command:**
```bash
bash -c "apt-get update -qq && apt-get install -y git && rm -rf /workspace/rag-pipeline && git clone https://github.com/frytos/llamaIndex-local-rag.git /workspace/rag-pipeline && cd /workspace/rag-pipeline && chmod +x scripts/runpod_startup.sh && SETUP_POSTGRES=1 DOWNLOAD_MODELS=1 bash scripts/runpod_startup.sh"
```

**8. Deploy!**

---

## üéØ Ce Que Fait le Startup Script

### Automatiquement:

1. ‚úÖ Affiche les infos GPU (nvidia-smi)
2. ‚úÖ Clone ton repo (ou pull si d√©j√† clon√©)
3. ‚úÖ Cr√©e un virtual environment Python
4. ‚úÖ Installe toutes les d√©pendances (requirements.txt)
5. ‚úÖ Installe PyTorch 2.4.0 avec CUDA 12.4
6. ‚úÖ Charge la configuration (runpod_config.env)
7. ‚úÖ Setup PostgreSQL (si SETUP_POSTGRES=1)
8. ‚úÖ Test le GPU + PyTorch
9. ‚úÖ Pr√©-t√©l√©charge les mod√®les (si DOWNLOAD_MODELS=1)
10. ‚úÖ Affiche un r√©sum√© + commandes utiles

### Temps total: ~2-3 minutes

---

## üìä Apr√®s le Startup

### V√©rifier que tout fonctionne:

```bash
# Se connecter au pod (Web Terminal ou SSH)
cd /workspace/rag-pipeline
source .venv/bin/activate

# Tester le GPU
python3 -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}')"

# Tester PostgreSQL (si install√©)
psql -h localhost -U fryt -d vector_db -c "SELECT version();"

# Run une query test
python3 rag_low_level_m1_16gb_verbose.py --query-only \
  --query "test query"
```

---

## üîß Troubleshooting

### Le script ne d√©marre pas

**Probl√®me:** `git: command not found`
**Solution:** Le one-liner installe git automatiquement, mais si tu utilises un custom template, assure-toi que git est install√©:
```bash
apt-get update && apt-get install -y git
```

### PyTorch n'a pas CUDA

**Probl√®me:** `torch.cuda.is_available() = False`
**Solution:** V√©rifie que tu utilises bien le template **PyTorch 2.4.0** avec CUDA support. Runpod a parfois des templates CPU-only par erreur.

### PostgreSQL connection refused

**Probl√®me:** `could not connect to server`
**Solution:**
```bash
# V√©rifier si PostgreSQL est d√©marr√©
service postgresql status

# Le d√©marrer si n√©cessaire
service postgresql start

# Tester la connexion
psql -h localhost -U fryt -d vector_db
```

### Repo d√©j√† existe (erreur git clone)

**Probl√®me:** `fatal: destination path already exists`
**Solution:** Le script d√©tecte automatiquement et fait un `git pull` au lieu de `clone`. Si probl√®me persiste:
```bash
rm -rf /workspace/rag-pipeline
# Puis relance le script
```

---

## üí° Tips & Best Practices

### 1. Utilise un Volume Persistant

Configure un **Network Volume** dans Runpod pour:
- `/workspace/rag-pipeline` (ton code)
- `/workspace/huggingface_cache` (mod√®les pr√©-t√©l√©charg√©s)
- `/var/lib/postgresql` (donn√©es PostgreSQL)

**Pourquoi?** Les volumes persistent m√™me si tu stop/restart le pod. Tu ne repays pas le download des mod√®les!

### 2. Fork le Repo

Au lieu d'utiliser mon repo, fork-le et utilise ton propre URL:
```bash
REPO_URL=https://github.com/TON-USERNAME/llamaIndex-local-rag.git
```

**Pourquoi?** Tu peux pusher tes modifications et le pod les pulera automatiquement.

### 3. Test en Local d'Abord

Avant de mettre le startup command dans Runpod, teste-le en local:
```bash
# Dans ton terminal local
bash scripts/runpod_startup.sh
```

### 4. Monitore les Logs

Pendant le premier startup:
```bash
# Dans le Web Terminal Runpod
tail -f /workspace/rag-pipeline/*.log
```

### 5. Stop/Start Workflow

Pour √©conomiser:
1. **Start:** Le startup script setup tout automatiquement
2. **Work:** Fais tes benchmarks/tests
3. **Stop:** Arr√™te le pod
4. **Restart:** Le script pull les derniers changements et repart

---

## üöÄ Quick Start - TL;DR

### M√©thode Ultra-Rapide:

1. **Runpod UI** ‚Üí Deploy GPU Pod
2. **Template:** PyTorch 2.4.0
3. **GPU:** RTX 4090
4. **Docker Command:**
```bash
bash -c "apt-get update -qq && apt-get install -y git && rm -rf /workspace/rag-pipeline && git clone https://github.com/frytos/llamaIndex-local-rag.git /workspace/rag-pipeline && cd /workspace/rag-pipeline && chmod +x scripts/runpod_startup.sh && SETUP_POSTGRES=1 DOWNLOAD_MODELS=1 bash scripts/runpod_startup.sh"
```
5. **Deploy!**
6. Attends 2-3 minutes
7. **Connect** ‚Üí Web Terminal
8. **Run:**
```bash
cd /workspace/rag-pipeline
source .venv/bin/activate
python3 rag_low_level_m1_16gb_verbose.py --query-only --query "test"
```

**C'est tout!** üéâ

---

## üìö R√©f√©rences

- Script source: `scripts/runpod_startup.sh`
- Config exemple: `runpod_config.env`
- Guide complet: `RUNPOD_DEPLOYMENT_GUIDE.md`
- Runpod Docs: https://docs.runpod.io/

---

## üÜò Besoin d'Aide?

Si quelque chose ne marche pas:
1. Check les logs: `cat /workspace/rag-pipeline/setup.log`
2. V√©rifie GPU: `nvidia-smi`
3. Test PyTorch: `python3 -c "import torch; print(torch.cuda.is_available())"`
4. Demande-moi! üí¨
