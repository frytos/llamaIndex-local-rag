# Runpod Configuration for RAG Pipeline
# Copy this to your Runpod pod and source it: source runpod_config.env

# ==========================================
# GPU Configuration (NVIDIA CUDA)
# ==========================================
export EMBED_BACKEND=torch          # Use PyTorch instead of MLX
export CUDA_VISIBLE_DEVICES=0       # Use first GPU

# ==========================================
# LLM Configuration (Optimized for RTX 4090)
# ==========================================
export N_GPU_LAYERS=99              # Offload all layers to GPU
export N_BATCH=512                  # Large batch size (24GB VRAM)
export CTX=16384                    # 4x larger context window
export MAX_NEW_TOKENS=1024          # 2x longer responses
export TEMP=0.1
export N_THREADS=8

# ==========================================
# Embedding Configuration
# ==========================================
export EMBED_MODEL=BAAI/bge-small-en
export EMBED_DIM=384
export EMBED_BATCH=256              # 2x larger than M1 (more VRAM)

# ==========================================
# PostgreSQL Configuration
# ==========================================
# Option 1: Local PostgreSQL on Runpod
export PGHOST=localhost
export PGPORT=5432

# Option 2: External managed PostgreSQL (recommended)
# export PGHOST=your-postgres-host.com
# export PGPORT=5432

export PGUSER=fryt
export PGPASSWORD=frytos
export DB_NAME=vector_db

# ==========================================
# RAG Configuration
# ==========================================
export CHUNK_SIZE=700
export CHUNK_OVERLAP=150
export TOP_K=5
export HYBRID_ALPHA=0.5
export MMR_THRESHOLD=0.5
export ENABLE_FILTERS=1

# ==========================================
# Logging
# ==========================================
export LOG_FULL_CHUNKS=1
export COLORIZE_CHUNKS=1
export LOG_QUERIES=1
export LOG_LEVEL=INFO

# ==========================================
# Paths
# ==========================================
export PDF_PATH=/workspace/data
export PGTABLE=messenger_runpod

# ==========================================
# Optional: HuggingFace Cache
# ==========================================
export HF_HOME=/workspace/huggingface_cache
export TRANSFORMERS_CACHE=/workspace/huggingface_cache

# ==========================================
# Usage
# ==========================================
# source runpod_config.env
# python3 rag_low_level_m1_16gb_verbose.py --query-only --query "your query"
